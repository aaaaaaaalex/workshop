
# Churning Nexthops Breaks Persistent Connections

As mentioned previously, if the router is forced to change
nexthop for an existing connection's traffic, the connection
is at-risk of landing on a Calico node which does not
recognize the it, and being dropped.

Let's prepare to simulate a node churn event which will show this
condition happening.

## Discover Which Calico Node is Performing Loadbalancing for The Persistent Connection.

Open a second terminal and check which node is currently handling
the loadbalancing step of the packet journey, by inspecting each
calico-node's BPF conntrack state. We will search the state for an
entry containing our service-IP, and the TCP state **"SYN-SENT"**.

We look for "SYN-SENT" because a loadbalancing node forwarding traffic
to another node will never see a TCP response when DSR is enabled (the
packet flies straight home instead of going back through the loadbalancing node).

```sh
# Get all calico-node pod names in the calico-system namespace.
calico_nodes=$(kubectl get po -n calico-system -l k8s-app=calico-node -o json  | jq -r .items.[].metadata.name)

# Get the service loadbalancer IP
longlived_svc_ip=$(kubectl get svc http-longlived-server -o json | jq -r .status.loadBalancer.ingress[].ip)

# Query each calico-node pod for an established connection to the service IP.
for c in ${calico_nodes}; do 
  echo "$c:";
  kubectl -n calico-system exec $c -c calico-node -- calico-node -bpf conntrack dump | grep -e "${longlived_svc_ip}.*SYN-SENT";
  done
```

This yields the output similar to the following:

```
calico-node-nwnxp:
TCP <node_ext_priv_ip>:50378 -> <longlived_svc_ip>:80 -> <backing_pod_ip>:9000 external client, service forwarded to/from <another_node_ip>  Active ago 4.158847527s SYN-SENT
calico-node-r22kg:
calico-node-t4rvn:
```

Note that I've replace my own cluster's IPs in the above log-output with
more meaningful names such as `<node_ext_priv_ip>`, `<longlived_svc_ip>`,
and `<backing_pod_ip>`.

If you can't find a "SYN-SENT" conntrack, then you can assume the loadbalancing
node is forwarding the traffic to a node-local pod and not tunneling it to 
any other node.

My pod `calico-node-nwnxp` has a "SYN-SENT" entry for our connection, so
it is forwarding the service traffic to a backing node/pod. Your pod name
will differ.

Additionally, the source-IP of the entry matches an IP assigned to my
particular router instance.

If you see many conntrack entries, i.e. from creating many connections,
you might discern your most-recently active connection as the entry
with the lowest-value "Active ago" field.


## Get The IP for The LoadBalancing Calico Node Pod.

```sh
forwarding_calico_node=[your loadbalancing calico-node name]
forwarding_calico_node_ip=$(kubectl -n calico-system get po ${forwarding_calico_node} -o json | jq -r .status.podIP)
```

## Discover Which Node Hosts The Chosen Backing Pod

When we opened our persistent connection, the chosen backing pod returned it's
name to us. With `kubectl get po <pod name> -o json | jq -r '.spec.hostIP'` we
can get the IP of the backing calico-node.


```sh
backing_calico_node_ip=[your backing pod's hostIP]
```

## A Word on Prioritising ECMP Routes

We will disrupt the router's connectivity to both the loadbalancing node, and the backing
node. In other words, we will force the router to send traffic to our spare node (the 3rd
one, which is neither the hosting, nor loadbalancing node.)

You'll recall we added an ECMP route that loadbalances **all** possible loadbalancer IPs in
the pool we created.

To disrupt the traffic over some of our nodes, we _could_ remove all hops from the ECMP route
bar the hop we want to force traffic down. However, having _no routes at all_ to a given node
might lead to dreaded _"martian packet"_ issues.

We could also increase the weight of our prioritised nexthop to 100, giving it a near-guaranteed
chance of being picked.

However, to **guarantee** traffic goes where we want it with absolute certainty, I'm going
to add a _more-specific route to the service IP_. Linux will pick the best-matching route
for traffic, so a more-specific route, say, `192.210.123.5/32`, will always be chosen over
a less-specific one, i.e. `192.210.123.0/24`.

## Monitor Service Traffic Leaving The Router

To verify whether traffic is flowing or not, I'll open another SSH terminal to the router,
and I'll run `tcpdump` to capture traffic. You may need to tweak the interface-name for your
own environment:

```sh
tcpdump -i ens5 host ${longlived_svc_ip}
```

If traffic is flowing normally, this will log packets flowing in both directions.
However, if the router cannot reach the backend, it will repeatedly re-transmit packets
in the same direction, and no response packets will come back.

I'll leave that running, and move onto the next step.

## Exclude the LoadBalancing-Node, and the Backing-Node IPs from the Router's ECMP Route.

Finally, on yet-another SSH to the router, I'll now add a route which directly targets the
`http-longlived-server` loadbalancer IP, in my case that's `192.210.123.5`, but your's may
be different, you can always check it with:

```sh
kubectl get svc http-longlived-server -o json | jq -r '.status.loadBalancer.ingress[].ip'
```

Just before disrupting traffic, go back to your persistent connection terminal and check
it hasn't exited. Send some data, then check your `tcpdump` output to verify traffic is flowing
in both directions, without retransmissions.

Finally, disrupt traffic by forcing it over a different hop:

```sh
longlived_svc_ip=[your loadbalancer IP]
prioritised_node=[the IP of the node to prioritise]
ip route add ${longlived_svc_ip} via ${prioritised_node} dev ens5
```

Now, send some more data over the persistent connection terminal, and check the `tcpdump` output.
You should see the same traffic being retransmitted, with no packets returning.


## Enable Maglev For The Service.

Now that we have shown the issues with traffic flowing over different Calico Nodes, we can
kill our open persistent connection, and solve the multi-path problem by enabling Maglev for
the service:

```sh
kubectl annotate svc http-longlived-server lb.projectcalico.org/external-traffic-strategy=maglev
```

## Repeat!

Remove the prioritising route from the router:

```sh
ip route del ${longlived_svc_ip}
```

Repeat the steps outlined in this page with Maglev enabled for the service. 
When it comes time to add the prioritising route, the connection will not break.
Instead, traffic will happily flow over to prioritised calico-node to the backing pod.